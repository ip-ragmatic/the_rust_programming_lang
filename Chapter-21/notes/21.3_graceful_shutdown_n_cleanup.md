# Graceful Shutdown and Cleanup

The next thing to implement is the `Drop` trait to call `join` on each of the threads in the pool so
they can finish the requests they're working on before closing. Then we'll implement a way to tell
the threads they should stop accepting new requests and shut down. We'll modify our server to accept
only two requests before gracefully shutting down its thread pool.

## Implementing the `Drop` Trait On `ThreadPool`

When the pool is dropped, our threads should all join to make sure they finish their work. The
following shows a first attempt at a `Drop` implementation; this code won't quite work yet.

```rust
impl Drop for ThreadPool {
    fn drop(&mut self) {
        for worker in &mut self.workers {
            println!("Shutting down worker {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}
```
```$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0507]: cannot move out of `worker.thread` which is behind a mutable reference
  --> src/lib.rs:52:13
   |
52 |             worker.thread.join().unwrap();
   |             ^^^^^^^^^^^^^ ------ `worker.thread` moved due to this method call
   |             |
   |             move occurs because `worker.thread` has type `JoinHandle<()>`, which does not implement the `Copy` trait
   |
note: `JoinHandle::<T>::join` takes ownership of the receiver `self`, which moves `worker.thread`
  --> /rustc/eeb90cda1969383f56a2637cbd3037bdf598841c/library/std/src/thread/mod.rs:1778:17

For more information about this error, try `rustc --explain E0507`.
error: could not compile `hello` (lib) due to 1 previous error
```

The error tells us we can't call `join` because we only have a mutable borrow of each `worker` and
`join` takes ownership of its argument. To solve this issue, we need to move the thread out of the
`Worker` instance that owns thread so `join` can consume the thread. We did this in Chapter 17: if
`Worker` holds an `Option<thread::JoinHandle<()>>` instead, we can call the `take` method on the
`Option` to move the value out of the `Some` variant and leave a `None` variant in its place. In
other words, a `Worker` that's running will have a `Some` variant in `thread`, and when we want to
clean up a `Worker`, we'll replace `Some` with `None` so the `Worker` doesn't have a thread to run.

Update `Worker` and its `new` like so:

```rust
struct Worker {
    id: usize,
    thread: Option<thread::JoinHandle<()>>,
}

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread  = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv().unwrap();

            println!("Worker {id} got a job. Executing...");

            job();
        });

        Worker { id, thread: Some(thread) }
    }
}
```

And then change the `drop` implementation for `ThreadPool` to this:

```rust
impl Drop for ThreadPool {
    fn drop(&mut self) {
        for worker in &mut self.workers {
            println!("Dropping worker number {}", worker.id);

            if let Some(thread) = worker.thread.take() {
                thread.join().unwrap();
            }
        }
    }
}
```

- We use `if let` in the case where a `worker`'s `thread` has already been cleaned up.

## Signaling to the Threads to Stop Listening for Jobs

This code doesn't function the way we want it to yet. The issue is the logic in the closures run by
the threads of the `Worker` instances: we currently call `join`, but that won't shut down the
threads b/c they loop forever looking for jobs. If we try to drop our `ThreadPool` with our current
implementation of `drop`, the main thread will block forever waiting for the first thread to finish.

To fix this, we'll need a change in the `ThreadPool` `drop` implementation and then a change in the
`Worker` loop.

First, we'll change the `ThreadPool` `drop` implementation to explicitly drop the `sender` before
waiting for the threads to finish:

```rust
pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: Option<mpsc::Sender<Job>>,  // wrapped in an Option now
}
// --snip--
impl ThreadPool {
    pub fn new(size: usize) -> ThreadPool {
        // --snip--

        ThreadPool {
            workers,
            sender: Some(sender),  // wrapped in Some
        }
    }

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();  // as_ref turns an &Option<T> to Option<&T> (owned Option 
                                                           // with referenced content). &T is required for send to
                                                           // work.
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        drop(self.sender.take());  // drops the Sender from inside the self.sender Option.
                                   // take takes the value inside and leaves None.

        for worker in &mut self.workers {
            println!("Shutting down worker {}", worker.id);

            if let Some(thread) = worker.thread.take() {
                thread.join().unwrap();
            }
        }
    }
}
```

Dropping `sender` closes the channel, which indicates no more messages will be sent. When that
happens, all the calls to `recv` that the workere do in the infinite loop will return an error. In
the following, we change the `Worker` loop to gracefully exit the loop in that case, which means the
threads will finish when the `ThreadPool` `drop` implementation calls `join` on them.

```rust
impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread  = thread::spawn(move || loop {
            let msg = receiver.lock().unwrap().recv();
            
            match msg {
                Ok(job) => {
                    println!("Worker {id} got a job. Executing...");
                    job();
                },
                Err(_) => {
                    println!("Worker {id} disconnecting. Shutting down...");
                    break;
                }
            }

        });

        Worker { id, thread: Some(thread) }
    }
}
```

Now modify `main` to accept only two requests before gracefully shutting down the server. Know that
you wouldn't want a real-world web server to shut down after serving only two requests. The code
just demonstrates that the graceful shutdown and cleanup is in working order.

```rust
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);

    for stream in listener.incoming().take(2) {
        let stream = stream.unwrap();

        pool.execute(|| {
            handle_connection(stream);
        });
    }

    println!("Shutting down...");
}
```
```
Worker 0 got a job. Executing...
Shutting down...
Shutting down worker 0
Worker 2 got a job. Executing...
Worker 1 disconnecting. Shutting down...
Worker 3 disconnecting. Shutting down...
Worker 0 disconnecting. Shutting down...
Shutting down worker 1
Shutting down worker 2
Worker 2 disconnecting. Shutting down...
Shutting down worker 3
```

- `take` is defined in the `Iterator` trait and limits the iteration to the first two items at most.
  The `ThreadPool` will go out of scope at the end of `main`, and the `drop` implementation will
  run.
- The ordering of the workers and messages can be different on each running of the server.

Notice one interesting aspect of this particular execution: the `ThreadPool` dropped the `sender`,
and before any worker received an error, we tried to join worker 0. Worker 0 had not yet gotten an
error from `recv`, so the main thread blocked waiting for worker 0 to finish. In the meantime,
worker 3 received a job and then all threads received an error. When worker 0 finished, the main
thread waited for the rest of the workers to finish. At that point, they had all exited their loops
and stopped.

## Challenge

- [ ] Add more documentation to `ThreadPool` and its public methods.
- [ ] Add tests of the library's functionality.
- [ ] Change calls to `unwrap` to more robust error handling.
- [ ] Use `ThreadPool` to perform some task other than serving web requests.
- [ ] Find a thread pool crate on crates.io and implement a similar web server using the crate
  instead. Then compare its API and robustness to the thread pool we implemented.
