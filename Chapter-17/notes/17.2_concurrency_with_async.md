## Concurrency With Async

Many times, the APIs for working with concurrency using async are very similar to those for using
threads. Other times, they can be shaped quite differently. Even when the APIs look similar between
threads and async, they often have different behavior; and they nearly always have different
performance characteristics.

### Counting

The `trpl` crate supplies a `spawn_task` function which looks very similar to the `thread::spawn`
API, and a `sleep` function which is an async version of the `thread::sleep` API. We can use these
together to implement the same counting example as with threads:
```rust
use std::time::Duration;

fn main() {
    trpl::run(async {
        trpl::spawn_task(async {
            for i in 1..10 {
                println!("hi number {i} from the first task!");
                trpl::sleep(Duration::from_millis(500)).await;
            }
        });

        for i in 1..5 {
            println!("hi number {i} from the second task!");
            trpl::sleep(Duration::from_millis(500)).await;
        }
    });
}
```
- This version stops as soon as the `for` loop in the body of the main async block finishes, because
  the task spawned by `spawn_task` is shut down when the `main` function ends. If you want to run
  all the way to the completion of the task, you will need to use a `join` handle to wait for the
  first task to complete.
  - With threads, we used the `join` method to "block" until the thread was done running. We can use
    `await` to do the same thing since the task handle itself is a future. Its `Output` type is a
    `Result`, so we also `unwrap` it after awaiting it.
    ```rust
    handle.join().unwrap(); // threads
    handle.await.unwrap();  // tasks
    ```

Rewriting `main` body to wait for spawned task to finish out:
```rust
    trpl::run(async {
        let handle = trpl::spawn_task(async {
            for i in 1..10 {
                println!("hi number {i} from the first task!");
                trpl::sleep(Duration::from_millis(500)).await;
            }
        });
        for i in 1..5 {
            println!("hi number {i} from the second task!");
            trpl::sleep(Duration::from_millis(500)).await;
        }
        handle.await.unwrap();
    });
```

It looks like async and threads give the same basic outcomes, just with different syntax. The bigger
difference is that we didn't need to spawn another operating system thread to do this. In fact, we
don't even need to spawn a task here. Because async blocks compile to anonymous futures, we can put
each loop in an async block and have the runtime run them both to completion using `trpl::join`.

The `trpl::join` function is similar to `join` method on `JoinHandle` for threads spawned, but
instead for futures. When given two futures, it produces a single new future whose output is a tuple
with the output of each of the futures passed in once both complete.
```rust
    trpl::run(async {
        let fut1 = async {
            for i in 1..10 {
                println!("hi number {i} from the first task!");
                trpl::sleep(Duration::from_millis(500)).await;
            }
        };

        let fut2 = async {
            for i in 1..5 {
                println!("hi number {i} from the second task!");
                trpl::sleep(Duration::from_millis(500)).await;
            }
        };

        trpl::join(fut1, fut2).await;
    });
```
- we use `trpl::join` to wait for both `fut1` and `fut2` to finish. We don't await `fut1` and `fut2`,
  but instead await the new future produced by `trpl::join`. We ignore the output, because it's just
  a tuple with two unit values in it.
- here, you'll see the exact same output every time, which is different from threads. That's because
  `trpl::join` is *fair*, meaning it checks each future equally often (alternating) and never lets
  one race ahead of the other if it's ready. Whereas with threads, the OS decides which thread to
  check and how long to let it run.
  - With async Rust, the runtime decides which task to check. Runtimes don't have to guarantee
    fairness for any given operation, and often offer different APIs to let us choose whether we
    want fairness or not.
    - wrt runtime checks for tasks, the details get complication b/c an async runtime might use OS
      threads under the hood as part of how it manages concurrency, so guaranteeing fairness can be
      more work for a runtime (but still possible).

Try some of these variations on awaiting the futures and see what happens (comment out the
`trpl::join` at the end for each variant):
- Remove the async block from around either or both of the loops.
  - Doing this results in task 1 running to completion before task 2 begins.
- Await each async block immediately after defining it.
  - Same as the previous variant, task 1 runs to completion before task 2 starts.
- Wrap only the first loop in an async block, and await the resulting future after the body of
  second loop.
  - Now task 2 runs to completion before task 1 starting.

### Message Passing

Sharing data between futures will feel familiar. We'll use message passing again, but this time with
async versions of the types and functions

Single async block:
```rust
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let val = String::from("hi");
        tx.send(val).unwrap();
        
        let recv = rx.recv().await.unwrap();
        println!("Got: {recv}");
    })
```
- The receiver `rx` is now mutable (immutable for thread version), and its `recv` creates a future
  that needs to be awaited on rather than producing the value directly.
- We don't have to spawn a separate thread or task, just need to await `rx.recv` call.
- `Receiver::recv` in `std::mpsc::channel` blocks until it receives a message.
  `trpl::Receiver::recv` doesn't b/c it's async. Instead of blocking, it hands control back to the
  runtime until either a message is received or the send side of the channel closes. By contrast, we
  don't await the `send` call b/c it doesn't block. It doesn't need to since the channel we're
  sending it into is unbounded.
  > Note: Because all of this async code runs in an async block in a `trpl::run` call, everything
  > within it can avoid blocking. However, the code outside it will block on the `run` function
  > returning. That is the whole point of the `trpl::run` function: it lets you choose where to
  > block on some set of async code, and thus where to transition between sync and async code

#### Add Concurrency to Previous Code

Rust doesn't have a way to write a for loop over an asynchronous series of items. So instead we'll the `while let` conditional loop (woah). A `while let` loop is the loop version of the `if let` construct. The loop will continue executing as long as the pattern it specifies continues matching.

As it stands, if we modified the above to do a `while let Some(value) = rx.recv.await`, the program wouldn't end and would need to shut it down with Ctrl-C. The reason is that there's only one async block, so everything in it runs linearly (no concurrency). All the `tx.send` calls happen, interspersed with all of the `trpl::sleep` calls and their associated await points. Only then does the `while let` loop get to go through any of the `.await` points on the `recv` calls.

So to get the behavior we want, messages received with sleep delays between them, `tx` and `rx` need to go into their own async blocks, and then we can pass them into `trpl::join` to have the runtime drive them separately. Also, we await the `trpl::join`, not the individual features (doing so cause a sequential flow, not good).

But, this isn't enough. The program still wouldn't end b/c of the way `while let` and `trpl::join`
interact:
- The future returned from `trpl::join` only completes once both futures passed to it have
  completed.
- The `tx` future would complete once finishing sleeping after sending the last message in the
  values to send vector.
- The `rx` future wouldn't complete until the `while let` loop ends.
- The `while let` loop wouldn't end until awaiting `rx.recv` produces `None`.
- Awaiting `rx.recv` will only return `None` once the other end of the channel is closed.
- The channel would only close if we called `rx.close` or when the sender side (`tx`) drops.
- `rx.close` isn't called anywhere, and `tx` won't be dropped until the outermost async block passed
  to `trpl::run` ends.
- The block can't end because it's blocked on `trpl::join` completing, which takes us back to the
  top of this list!
  
We could manually call `rx.close` somewhere, but that wouldn't make much sense. Stopping after handling some arbitrary number of messages would end the program, but we could miss messages. So what is there to do? Well, the async block where messages would be sent *borrows* `tx`. But if it were moved into the async block, then `tx` would get dropped once the block ends (think `move` and threads). We can apply the same thing to async blocks with `async move`!

Let's send receive multiple messages over the async channel:
```rust
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx_fut = async move {
            let msgs = vec![
                String::from("hi"),
                String::from("from"),
                String::from("the"),
                String::from("future"),
            ];
            for msg in msgs {
                tx.send(msg).unwrap();
                trpl::sleep(Duration::from_millis(250)).await;
            }
        };  // tx gets dropped here, no more transmitter
            
        let rx_fut = async {
            while let Some(val) = rx.recv().await{
                println!("received: `{val}`");
            }
        };
        trpl::join(tx_fut, rx_fut).await;
    });
```

This async channel is also a multi-producer channel, so we can clone `tx` and apply the same `async move` block to it's clone. e.g.:
```rust
        let (tx, mut rx) = trpl::channel();
        let tx1 = tx.clone();
        let tx_fut = async move {
            // ...
            tx.send(msg).unwrap();
            // ...
        };
        let tx1_fut = async move {
            // ...
            tx1.send(msg).unwrap();
            // ...
        };
```

### Quiz

1. Consider the following function:
    ```rust
    async fn print_letters() {
        let a = async { print!("A"); };
        let b = async { print!("B"); };
        let c = async { print!("C"); };
        c.await;
        b.await;
        a.await;
    }
    ```
    Which of the following strings can possibly be printed after running `print_letters().await`?

***Answer:*** `CBA`
- This program has deterministic behavior. The prints do not execute until the async blocks are
  awaited. The blocks are awaited in the order c/b/a, so the program will only print CBA.
--- 
2. Say you are given a helper function `wait_all(a, b)` with the following behavior:
    - `wait_all` guarantees that a and b are executed to completion.
    - `wait_all` makes no guarantees regarding fairness or initial execution order.
    
    Then given the following code:
    ```rust
    async fn print_letters() {
        let fut1 = async { 
            print!("A");
            sleep().await;
            print!("B");
        };
        let fut2 = async {
            print!("C");
            sleep().await;
            print!("D");
        }
        wait_all(fut1, fut2).await;
    }
    ```
    Which of the following strings can possibly be printed after running `print_letters().await`?

***Answer:*** `ABCD`, `ACBD`, `CADB`
- The hypothetical `wait_all` primitive is like `join` but with fewer guarantees. Given only the
  spec in this problem, any interleaving of the two futures is valid. The only invalid output is one
  that inverts program execution order, i.e., `DABC` which would have D printed before C (not
  possible).
---
3. Say you are given a message-passing channel `channel()` which is non-blocking and *bounded*, meaning
   `send` returns a future that completes once there is capacity in the channel. Assume you also have
   a function `join(a, b)` which *fairly* waits on both its arguments to completion. Then given this
   async code:
    ```rust
    let (tx, mut rx) = channel(16);
    let recv_fut = rx.recv();
    let send_fut = tx.send(0);
    let (n, _) = join(recv_fut, send_fut).await;
    println!("{}", n.unwrap());
    ```
    What will happen as a result of executing this code?

***Answer:*** The program prints `0` and exits.
- Because the channel is non-blocking, we can create a receive future before sending without looping forever.