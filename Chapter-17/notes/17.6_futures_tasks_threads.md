## Futures, Tasks, and Threads

So why, for implementing concurrency, choose threads or async with futures and streams? The answer
is: it depends! In many cases, it's not threads or async, but rather ***threads and async***.

Many OSs have supplied threading-based concurrency models for decades now, and many programming
languages have support for them as a result. However, they're not without their tradeoffs. Many OSs
use a fair bit of memory for each thread, and come with some overhead for starting up and shutting
down. Threads are also only an option when the OS and hardware support them! Unlike mainstream
desktop and mobile computers, some embedded systems do not have an OS at all, so they also won't
have threads!

The async model provides a different (and ultimately complementary) set of tradeoffs. In the async
model, concurrent operations don't require their own threads. Instead, they can run on tasks, as
when we used `trpl::spawn_task` to kick off work within a synchronous function throughout the
streams sections. A task is a lot like a thread, but instead of being managed by the OS, it's
managed by library-level code: the runtime.

In a previous section, we saw that we could build a `Stream` by using an async channel and spawning
an async task, which could be called from synchronous code. The same thing can be done with a
thread!

However, there is a major difference between the two approaches behave. We could spawn hundreds of
thousands or even millions of async tasks on any modern personal computer, but if we did that with
threads, we would run out of memory!

But, there's a reason these APIs are so similar. Threads act as a boundary for sets of synchronous
operations; concurrency is possible *between* threads. Tasks act as a boundary for sets of
asynchronous operations; concurrency is possible both *between and within tasks*. In that regard,
tasks are kind of like lightweight, runtime-managed threads with added capabilities coming from
being managed by a runtime (instead of the OS). Futures are an even more granular unit of
concurrency, where each future may represent a tree of other futures. That is, the runtime manages
tasks and tasks manage futures.

This doesn't mean async tasks are always better than threads, any more than that threads are better
than tasks.

On one hand, concurrency with threads is in many ways a simpler programming model than concurrency
with async. Threads are somewhat "fire and forget," they have no native equivalent to a future, so
they simply run to completion without interruption (except by the OS). That is, they have no
intra-task concurrency like futures can. Threads in Rust also have no mechanisms for cancellation.
- Cancellation is a subject we haven't covered in depth yet, but is implicit in the fact that
  whenever we ended a future, its state got cleaned up correctly.

These limitations make threads harder to compose than futures. e.g. it's more difficult to build
something like the `timeout` we built in "Building Our Own Async Abstractions", or the `throttle`
method we used with streams in "Composing Streams". The fact that futures are richer data structures
means they can be composed together more naturally.

Tasks then give additional control over futures, allowing the choice of where and how to group them.
But it turns out that threads and tasks often work very well together, because tasks can be moved
around between threads. We have not mentioned it up until now, but under the hood, the `Runtime` we
have been using (the `spawn_blocking` and `spawn_task` functions, for example) is multithreaded by
default! Many runtimes use an approach called *work stealing* to transparently move tasks around
between threads based on the current utilization of the threads, with the aim of improving the
overall performance of the system. To build that actually requires both threads and tasks, and
therefore futures.

As a default way of thinking about when to use which:
- If the task is ***very parallelizable***, like processing a bunch of data where each part can be
  processed separately, threads are a better choice.
- If the task is ***very concurrent***, like handling messages from a bunch of different sources
  which may come in a different intervals or different rates, async is a better choice.
  
And if you need some mix of parallelism and concurrency, you do not have to choose between threads and async. You can use them together freely, letting each one serve the part it is best at. For example:

```rust
use std::{thread, time::Duration};

fn main() {
    let (tx, mut rx) = trpl::channel();

    thread::spawn(move || {
        for i in 1..11 {
            tx.send(i).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    trpl::run(async {
        while let Some(message) = rx.recv().await {
            println!("{message}");
        }
    });
}
```

To return to the examples the chapter was opened with: we could run a set of video encoding tasks
using a dedicated thread (since video encoding is compute bound), but notify the UI that those
operations are done with an async channel.

Whether with threads, with futures and tasks, or with the combination of both, Rust provides the
tools needed to write safe, fast, concurrent code. Whether for a high-throughput web server or an
embedded operating system.